So what you should do is take a look at the data for the current timelines as they're being generated. What I mean is just look in the storage for the current timelines. Then take a look at the codes that's used to generate those timelines.

The purpose so the way the timeline is going to be used is that it's going to be given as context to an LLM. Right. And the LLM will then be asked to extend the timeline into the future.

So what's important about the this process is that we want to make a full use of the context length available that's available to the LLM that we're doing this timeline extension process.

So the actual present timelines that we generate by my estimation They should aim to take up you know maybe 50% maybe even more 60% of the um context available to the the future timeline generation

Right, so that's  kind of desirable state with these timelines and then you can take a look at how the timeline is generated and see are the present timelines long enough if they're not what can we change to make those timelines long enough 

                    