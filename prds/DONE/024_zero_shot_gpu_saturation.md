So for the zero shot politics classifier while it's running, I'm I look at NV T top, and I see that GPU memory consumption is around twenty percent and GPU overall utilization is around thirty percent. So I would prefer to maximally saturate the GPU while this process is running. So maybe assuming we're still just staying on hugging face um inference, what can uh what configuration options or batch size uh choices can we make to improve GPU utilization to make the process run faster.